# â˜ï¸ AWS Cloud Computing Experiments â€“ Free Tier Labs

This repository contains detailed step-by-step AWS Cloud experiments demonstrating essential cloud services such as EC2, S3, RDS, DynamoDB, SNS, SQS, Rekognition, SageMaker, and more â€” all using the **AWS Free Tier**.

---

## ğŸ§ª Experiment 1: Launch an EC2 Instance and Connect via SSH

### ğŸ¯ Objective
To learn how to launch and configure a virtual server using Amazon EC2, set up security groups, and connect to the instance using SSH.

### ğŸ Outcome
Students will be able to launch an EC2 instance, configure its security settings, and establish a secure connection using SSH.

### âš™ï¸ Step-by-Step Procedure
1. Open [AWS](https://aws.amazon.com/) and sign in.
2. Navigate to **EC2 Dashboard** â†’ Click **Launch Instance**.
3. Name your instance (e.g., `MyEC2Instance`).
4. Choose **Amazon Linux 2 AMI (Free Tier eligible)**.
5. Select instance type: `t2.micro`.
6. Create a **Key Pair** â†’ select `.pem` format â†’ download securely.
7. Configure Security Group â†’ Add Rule:
   - **Type:** SSH  
   - **Protocol:** TCP  
   - **Port:** 22  
   - **Source:** My IP
8. Launch the instance and wait for it to run.
9. Copy the **Public IPv4 address**.
10. Change key permission:
   ```bash
   chmod 400 your-key-name.pem
   ```
11. Connect using SSH:
   ```bash
   ssh -i "your-key-name.pem" ec2-user@<your-ec2-public-ip>
   ```

### ğŸ§© Description
An **Amazon EC2 (Elastic Compute Cloud)** instance is a virtual server in AWS providing scalable computing power. It allows flexible configurations of CPU, memory, storage, and OS to meet user needs. Common uses include web hosting, data analysis, and ML workloads. With secure access via IAM, key pairs, and security groups, EC2 offers reliability, scalability, and cost-effectiveness.

---

## ğŸ§ª Experiment 2: Create an Amazon SQS Queue and Send Messages Using AWS CLI

### ğŸ¯ Objective
To understand how to create and manage **Simple Queue Service (SQS)** queues and send messages using AWS CLI.

### ğŸ Outcome
Students will learn to create an SQS queue and manage messages via CLI commands.

### âš™ï¸ Step-by-Step Procedure
1. Install AWS CLI â†’ [Download here](https://aws.amazon.com/cli/)
2. Configure CLI:
   ```bash
   aws configure
   ```
   Enter:
   - Access Key ID  
   - Secret Access Key  
   - Region (e.g., us-east-1)  
   - Output format: `json`
3. Create a queue:
   ```bash
   aws sqs create-queue --queue-name MyQueue
   ```
4. List queues:
   ```bash
   aws sqs list-queues
   ```
5. Get queue URL:
   ```bash
   aws sqs get-queue-url --queue-name MyQueue
   ```
6. Send a message:
   ```bash
   aws sqs send-message --queue-url <your-queue-url> --message-body "Hello from Cloud Lab"
   ```
7. Receive the message:
   ```bash
   aws sqs receive-message --queue-url <your-queue-url>
   ```

### ğŸ§© Description
**Amazon SQS** is a fully managed message queuing service for decoupling distributed systems. It supports asynchronous communication between microservices and ensures reliability through **Standard** and **FIFO** queue types.

---

## ğŸ§ª Experiment 3: Create an SNS Topic, Subscribe via Email, and Publish a Message

### ğŸ¯ Objective
To demonstrate how to use **Amazon SNS** to create topics, subscribe endpoints, and publish messages.

### ğŸ Outcome
Students will create an SNS topic, subscribe via email, and send notifications.

### âš™ï¸ Step-by-Step Procedure
1. Open **Simple Notification Service (SNS)** in AWS.
2. Create a **Standard topic** named `MyTopic`.
3. Create a **Subscription**:
   - Protocol: Email  
   - Endpoint: Your valid email
4. Confirm subscription via email.
5. Publish a message:
   - Subject: *Test Notification*  
   - Message: *This is a test message from AWS SNS.*

### ğŸ§© Description
**Amazon SNS** uses a publish-subscribe model for push-based communication across services and users. Itâ€™s widely used for event notifications, monitoring, and automation triggers.

---

## ğŸ§ª Experiment 4: Create an S3 Bucket and Upload Files

### ğŸ¯ Objective
To learn how to create and manage an **Amazon S3** bucket.

### âš™ï¸ Step-by-Step Procedure
1. Open **S3** service in AWS.
2. Click **Create bucket** â†’ give it a unique name.
3. Choose region â†’ leave defaults â†’ click **Create**.
4. Open bucket â†’ click **Upload** â†’ add files â†’ **Upload**.

### ğŸ§© Description
**Amazon S3 (Simple Storage Service)** is an object storage service for secure, scalable, and durable data storage. Common uses include website hosting, backups, and analytics.

---

## ğŸ§ª Experiment 5: Deploy a WordPress Website Using Amazon Lightsail

### ğŸ¯ Objective
To learn how to deploy a **WordPress** site using Lightsail Free Tier.

### âš™ï¸ Step-by-Step Procedure
1. Open **Amazon Lightsail**.
2. Create an instance â†’ Platform: Linux/Unix â†’ Blueprint: WordPress.
3. Choose Free Tier plan â†’ Name the instance â†’ Create.
4. Access WordPress at:
   ```
   http://<public-ip>
   ```
5. Admin login:
   ```
   http://<public-ip>/wp-admin
   ```
   Default user: `user`  
   Password: Retrieve via SSH â†’  
   ```bash
   cat bitnami_application_password
   ```

### ğŸ§© Description
**Lightsail** simplifies WordPress deployment by bundling compute, storage, and networking in one package with predictable pricing.

---

## ğŸ§ª Experiment 6: Configure AWS Backup for EC2 and Restore Data

### ğŸ¯ Objective
To automate EC2 backups using **AWS Backup**.

### âš™ï¸ Procedure
1. Open **AWS Backup** â†’ Create Backup Plan.
2. Define plan name, frequency, and retention.
3. Assign EC2 instance as resource.
4. Monitor backup job and restore from the vault when needed.

### ğŸ§© Description
**AWS Backup** centralizes automated backup management across services. It supports encryption, lifecycle rules, and compliance tracking.

---

## ğŸ§ª Experiment 7: Launch RDS MySQL Instance and Connect via MySQL Workbench

### ğŸ¯ Objective
To create and connect to an **Amazon RDS** MySQL database.

### âš™ï¸ Procedure
1. Open **Amazon RDS** â†’ Create Database.
2. Engine: MySQL â†’ Free Tier.
3. Configure credentials â†’ Enable public access â†’ Launch.
4. Connect using:
   - Hostname: RDS endpoint  
   - Port: 3306  
   - User & Password as configured  
5. Create database:
   ```sql
   CREATE DATABASE labdb;
   ```

### ğŸ§© Description
**Amazon RDS** provides scalable, managed relational databases with automated backups and patching.

---

## ğŸ§ª Experiment 8: Create a DynamoDB Table and Perform CRUD Operations

### âš™ï¸ Procedure
```bash
aws configure

aws dynamodb create-table   --table-name StudentRecords   --attribute-definitions AttributeName=StudentID,AttributeType=S   --key-schema AttributeName=StudentID,KeyType=HASH   --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1

aws dynamodb put-item   --table-name StudentRecords   --item '{"StudentID": {"S": "101"}, "Name": {"S": "John"}, "Dept": {"S": "CSE"}}'

aws dynamodb get-item   --table-name StudentRecords   --key '{"StudentID": {"S": "101"}}'

aws dynamodb delete-item   --table-name StudentRecords   --key '{"StudentID": {"S": "101"}}'
```

### ğŸ§© Description
**Amazon DynamoDB** is a fully managed NoSQL service supporting key-value and document data structures for high-performance applications.

---

## ğŸ§ª Experiment 9: Analyze an Image Using Amazon Rekognition

### âš™ï¸ Procedure
1. Upload image to S3 bucket.
2. Run:
   ```bash
   aws rekognition detect-labels      --image "S3Object={Bucket=my-bucket,Name=my-image.jpg}"      --max-labels 10      --min-confidence 70
   ```
3. Review JSON output for detected objects.

### ğŸ§© Description
**Amazon Rekognition** uses AI to detect objects, faces, and scenes in images and videos, providing powerful visual analysis capabilities.

---

## ğŸ§ª Experiment 10: Train a Simple ML Model Using Amazon SageMaker

### âš™ï¸ Procedure
1. Create **SageMaker Notebook Instance** â†’ `ml.t2.medium`.
2. Open Jupyter â†’ Python 3 kernel.
3. Run:
   ```python
   from sklearn.datasets import load_iris
   from sklearn.model_selection import train_test_split
   from sklearn.ensemble import RandomForestClassifier
   from sklearn.metrics import accuracy_score

   data = load_iris()
   X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)
   model = RandomForestClassifier()
   model.fit(X_train, y_train)
   predictions = model.predict(X_test)
   print("Model Accuracy:", accuracy_score(y_test, predictions))
   ```

### ğŸ§© Description
**Amazon SageMaker** offers a managed ML environment to build, train, and deploy models easily using Jupyter notebooks and built-in algorithms.

---

## ğŸ“˜ Author
**Laxmidhar Penta**

## ğŸ·ï¸ License
This project is licensed under the [MIT License](LICENSE).

---
